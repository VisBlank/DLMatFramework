{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution AutoEncoder\n",
    "\n",
    "![alt text](deep_autoencoder.png \"Deep Auto-encoder\")\n",
    "\n",
    "Basically 2 mirrored neural networks, where the center part (Latent code) will have a compressed representation of the input.\n",
    "![alt text](autoencoder_schema.jpg \"Auto-Encoder\")\n",
    "\n",
    "Now doing the whole thing with convs,pools,unpools,deconvs\n",
    "![alt text](CAE_Image.png \"Convolutional Auto-Encoder\")\n",
    "\n",
    "### Things that you could do\n",
    "* Pretrain a CONV network (Unsupervised training on imagenet, making the encoder a good feature detector)\n",
    "* Colorization\n",
    "* Latent space clustering (Use PCA/tsne on the squeezed part of the network)\n",
    "* Building block for other projects like Segnets\n",
    "\n",
    "References:\n",
    "\n",
    "* https://gist.github.com/tomokishii/7ddde510edb1c4273438ba0663b26fc6\n",
    "* https://github.com/pkmital/tensorflow_tutorials\n",
    "* https://github.com/chiphuyen/tf-stanford-tutorials\n",
    "* https://blog.dominodatalab.com/imbalanced-datasets/\n",
    "* https://pgaleone.eu/neural-networks/2016/11/24/convolutional-autoencoders/\n",
    "* https://pgaleone.eu/neural-networks/deep-learning/2016/12/13/convolutional-autoencoders-in-tensorflow/\n",
    "* https://swarbrickjones.wordpress.com/2015/04/29/convolutional-autoencoders-in-pythontheanolasagne/\n",
    "* https://gist.github.com/Newmu/a56d5446416f5ad2bbac\n",
    "* https://gist.github.com/kastnerkyle/f3f67424adda343fef40\n",
    "* https://github.com/Kaixhin/Autoencoders\n",
    "* https://github.com/siavashk/imagenet-autoencoder\n",
    "* https://siavashk.github.io/2016/02/22/autoencoder-imagenet/\n",
    "* http://torch.ch/blog/2015/11/13/gan.html\n",
    "* https://github.com/andreaazzini/segnet\n",
    "* https://github.com/tkuanlun350/Tensorflow-SegNet\n",
    "* https://github.com/shekkizh/FCN.tensorflow\n",
    "* http://techtalks.tv/talks/fully-convolutional-networks-for-semantic-segmentation/61606/\n",
    "* https://github.com/xiaofanglegoc/tensorflow-fcn\n",
    "* https://www.robots.ox.ac.uk/~vgg/rg/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf\n",
    "* http://stackoverflow.com/questions/36548736/tensorflow-unpoolingtensorflow/tensorflow#2169\n",
    "* https://arxiv.org/pdf/1412.7062.pdf\n",
    "* https://arxiv.org/pdf/1511.07122.pdf\n",
    "* https://hackernoon.com/autoencoders-deep-learning-bits-1-11731e200694\n",
    "* https://www.youtube.com/watch?v=eBbEDRsCmv4&t=446s\n",
    "* https://www.tensorflow.org/get_started/embedding_viz\n",
    "* http://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/\n",
    "* http://colah.github.io/posts/2014-10-Visualizing-MNIST/\n",
    "* https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/autoencoder.py\n",
    "* https://jmetzen.github.io/2015-11-27/vae.html\n",
    "* https://github.com/tensorflow/models/blob/master/autoencoder/autoencoder_models/Autoencoder.py\n",
    "* https://www.youtube.com/watch?v=H_Bi_PQWJJc\n",
    "* https://www.youtube.com/watch?v=z5ZYm_wJ37c\n",
    "* https://www.youtube.com/watch?v=pLC-zqttQJE\n",
    "* https://www.youtube.com/watch?v=Rdpbnd0pCiI\n",
    "* http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture13.pdf\n",
    "* https://medium.com/@juliendespois/latent-space-visualization-deep-learning-bits-2-bd09a46920df\n",
    "* https://github.com/tiny-dnn/tiny-dnn/issues/612\n",
    "* http://www.tensorflowexamples.com/2017/01/transposed-convnets-or-deconvolution.html\n",
    "* https://arxiv.org/pdf/1609.03677.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Force to see just the first GPU\n",
    "# https://devblogs.nvidia.com/parallelforall/cuda-pro-tip-control-gpu-visibility-cuda_visible_devices/\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2d Convolution\n",
    "def conv2d(x, k_h, k_w, channels_in, channels_out, stride, act_type='relu', name=\"conv\", viewWeights=False):\n",
    "    with tf.name_scope(name):\n",
    "        # Define weights\n",
    "        w = tf.Variable(tf.truncated_normal([k_h,k_w, channels_in, channels_out], stddev=0.1), name=\"weights\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[channels_out]), name=\"bias\")    \n",
    "        # Convolution\n",
    "        #conv = tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='SAME')    \n",
    "        conv = tf.nn.conv2d(x, w, strides=[1, stride, stride, 1], padding='SAME')    \n",
    "                \n",
    "        # Relu or sigmoid\n",
    "        if act_type == 'relu':\n",
    "            activation = tf.nn.relu(conv + b)\n",
    "        else:\n",
    "            activation = tf.sigmoid(conv + b)\n",
    "        \n",
    "        # Add summaries for helping debug\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"bias\", b)\n",
    "        tf.summary.histogram(\"activation\", activation)\n",
    "        \n",
    "        # Visualize weights if needed\n",
    "        if viewWeights == True:                        \n",
    "            tf.summary.image(\"W_grid\", put_kernels_on_grid(w,3,8), 1)            \n",
    "            \n",
    "        return activation\n",
    "\n",
    "# 2d Transposed convolution (Deconvolution)\n",
    "def conv2d_transpose(x, out_size, k_h, k_w, channels_in, channels_out, stride, act_type='relu', name=\"deconv\"):\n",
    "    with tf.name_scope(name):\n",
    "        # Define weights (Notice that out/in channels are swapped on transposed conv)\n",
    "        w = tf.Variable(tf.truncated_normal([k_h,k_w, channels_out, channels_in], stddev=0.1), name=\"weights\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[channels_out]), name=\"bias\")    \n",
    "        \n",
    "        # Image output shape\n",
    "        shape4D = [tf.shape(x)[0], out_size[0], out_size[1], channels_out]\n",
    "        # Deconvolution (Transposed convolution)\n",
    "        conv = tf.nn.conv2d_transpose(x, w, output_shape=shape4D, strides=[1, stride, stride, 1], padding='SAME')                \n",
    "        \n",
    "        # Relu or sigmoid\n",
    "        if act_type == 'relu':\n",
    "            activation = tf.nn.relu(conv + b)\n",
    "        else:\n",
    "            activation = tf.sigmoid(conv + b)\n",
    "        \n",
    "        # Add summaries for helping debug\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"bias\", b)\n",
    "        tf.summary.histogram(\"activation\", activation)                \n",
    "            \n",
    "        return activation    \n",
    "\n",
    "def max_pool(x, k_h, k_w, S, name=\"maxpool\"):\n",
    "    with tf.name_scope(name):\n",
    "        return tf.nn.max_pool(x, ksize=[1, k_h, k_w, 1],strides=[1, S, S, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def fc_layer(x, channels_in, channels_out, name=\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([channels_in, channels_out], stddev=0.1), name=\"weights\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[channels_out]), name=\"bias\")    \n",
    "        activation = tf.nn.relu(tf.matmul(x, w) + b)\n",
    "        # Add summaries for helping debug\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"bias\", b)\n",
    "        tf.summary.histogram(\"activation\", activation)\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model\n",
    "Basically what we want to build.\n",
    "![alt text](CAE_Tensorboard.png \"Convolutional Auto-Encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model input\n",
    "# Input placeholders\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# Reshape to MNIST image dimensions 28x28x1\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "##### ENCODER\n",
    "# K_y,K_x,in_depth,out_depth,stride\n",
    "conv1_out = conv2d(x_image, 3, 3, 1, 16, 1, act_type='relu', name=\"conv1\")        \n",
    "pool1_out = max_pool(conv1_out, 2, 2, 2, \"pool1\")        \n",
    "conv2_out = conv2d(pool1_out, 3, 3, 16, 8, 1, act_type='relu', name=\"conv2\")        \n",
    "pool2_out = max_pool(conv2_out, 2, 2, 2, \"pool2\")        \n",
    "conv3_out = conv2d(pool2_out, 3, 3, 8, 8, 1, act_type='relu', name=\"conv3\")    \n",
    "pool3_out = max_pool(conv3_out, 2, 2, 2, \"pool3\")\n",
    "\n",
    "##### DECODER\n",
    "# at this point the representation is (8, 4, 4) i.e. 128-dimensional\n",
    "# Decoding phase    \n",
    "conv_t1_out = conv2d_transpose(pool3_out, (7, 7), 3, 3, 8, 8, 2, act_type='relu', name=\"dconv1\")        \n",
    "conv_t2_out = conv2d_transpose(conv_t1_out, (14, 14), 3, 3, 8, 8, 2, act_type='relu', name=\"dconv2\")        \n",
    "conv_t3_out = conv2d_transpose(conv_t2_out, (28, 28), 3, 3, 8, 16, 2, act_type='relu', name=\"dconv3\")        \n",
    "\n",
    "# Just adapt volume to from 28x28x16 to 28x28x1\n",
    "decoded_img = conv2d(conv_t3_out, 1, 1, 16, 1, 1,act_type='sigmoid',name=\"conv_out\")        \n",
    "\n",
    "# Convert spatial result to a vector in order to match with input \"x\" shape\n",
    "decoded = tf.reshape(decoded_img, [-1, 784])\n",
    "\n",
    "# Reshape for summary\n",
    "decoded_img_sumary = tf.reshape(decoded_img, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where is the unpool?\n",
    "Due to indice unravel still unavailable in tensorflow, the original upsampling method is temporarily replaced simply by deconv( or conv-transpose) layer (without pooling indices). You can follow the issue here: https://github.com/tensorflow/tensorflow/issues/2169 (The current workaround for unpooling layer is a bit slow because it lacks of GPU support.)\n",
    "![alt text](maxunpool.png \"Max unpooling\")\n",
    "![alt text](UnpoolResults.png \"Max unpooling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and solver\n",
    "For this example we're using the binary cross-entropy bot other losses also work like mse and l2 loss.\n",
    "![alt text](Binary_Cross_Entropy.png \"Max unpooling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Binary cross-entropy\n",
    "with tf.name_scope(\"cross_entropy\"):\n",
    "    cross_entropy = -1. *x *tf.log(decoded) - (1. - x) *tf.log(1. - decoded)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    # Can also use l2 loss but you need to decrease the learning rate (0.01)\n",
    "    #loss = tf.nn.l2_loss(x-decoded)\n",
    "\n",
    "# Solver configuration\n",
    "with tf.name_scope(\"Solver\"):\n",
    "    train_step = tf.train.AdagradOptimizer(0.1).minimize(loss)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add some tensors to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add summary for loss, input images, output images\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "tf.summary.image(\"input\", x_image, 10)\n",
    "tf.summary.image(\"output\", decoded_img_sumary, 10)\n",
    "\n",
    "fc1_out_size = 8*4*4\n",
    "embedding = tf.Variable(tf.zeros([128, fc1_out_size]), name=\"test_embedding\")\n",
    "assignment = embedding.assign(tf.reshape(pool3_out, [128, fc1_out_size]))\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Avoid allocating the whole memory\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "#sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"/tmp/conv_autoencoder/1\")\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "  step, loss =      0:  0.690\n",
      "  step, loss =   1000:  0.226\n",
      "  step, loss =   2000:  0.161\n",
      "  step, loss =   3000:  0.152\n",
      "  step, loss =   4000:  0.134\n",
      "  step, loss =   5000:  0.127\n",
      "  step, loss =   6000:  0.124\n",
      "  step, loss =   7000:  0.122\n",
      "  step, loss =   8000:  0.118\n",
      "  step, loss =   9000:  0.117\n",
      "  step, loss =  10000:  0.118\n",
      "loss (test) =  0.112823\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "with sess:    \n",
    "    print('Training...')\n",
    "    for i in range(10001):\n",
    "        batch_xs, _ = mnist.train.next_batch(128)\n",
    "        train_step.run({x: batch_xs})\n",
    "        if i % 1000 == 0:\n",
    "            train_loss= loss.eval({x: batch_xs})\n",
    "            print('  step, loss = %6d: %6.3f' % (i, train_loss))\n",
    "        \n",
    "        # Dump summary (Avoid dump every iteration)\n",
    "        if i % 100 == 0:\n",
    "            s = sess.run(merged_summary, feed_dict={x:batch_xs})\n",
    "            writer.add_summary(s,i)\n",
    "            \n",
    "            # Save embedding (for PCA, TSNE)\n",
    "            sess.run(assignment, feed_dict={x: batch_xs})\n",
    "            saver.save(sess, os.path.join(\"/tmp/conv_autoencoder/\", \"model.ckpt\"), i)\n",
    "\n",
    "    # generate decoded image with test data        \n",
    "    #decoded_imgs = decoded.eval(feed_dict={x:mnist.test.images})\n",
    "    #print('loss (test) = ', loss.eval(feed_dict={x:mnist.test.images}))\n",
    "    # Avoid restarting my work PC (Avoid loading the whole validation batch)\n",
    "    batch_xs_val, _ = mnist.test.next_batch(128)\n",
    "    decoded_imgs = decoded.eval(feed_dict={x:batch_xs_val})\n",
    "    print('loss (test) = ', loss.eval(feed_dict={x:batch_xs_val}))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQAbwEAcAAAAAACAD/j/J+gy5AaKz0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f65c3d8fa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#x_test = mnist.test.images\n",
    "x_test = batch_xs_val\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('mnist_ae2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What else can be done with deconvs\n",
    "\n",
    "### Segmentation\n",
    "The architecture consists of a sequence of non-linear processing layers (encoders) and a corresponding set of decoders followed by a pixelwise classifier. Typically, each encoder consists of one or more convolutional layers with batch normalisation and a ReLU non-linearity, followed by non-overlapping maxpooling and sub-sampling. The sparse encoding due to the pooling process is upsampled in the decoder using the maxpooling indices in the encoding sequence (see the figure below). One key ingredient of the SegNet is the use of max-pooling indices in the decoders to perform upsampling of low resolution feature maps. This has the important advantages of retaining high frequency details in the segmented images and also reducing the total number of trainable parameters in the decoders.\n",
    "![alt text](SegnetArch.png \"Segnets\")\n",
    "Again is valid to remember that tensorflow does not support yet this operation and other projects do the unpooling operation by playing with the transposed convolution stride.\n",
    "\n",
    "### Depth estimation\n",
    "The authors proposed a fully convolutional encoder-decoder based network to extract a depth map from an image + optical flow estimation computed by the Brox algorithm. In addition to real training data, simulated data using the Unreal engine is used. This approach is intended as  a basis for an obstacle detection system.\n",
    "![alt text](DepthEstimation.png \"Segnets\")\n",
    "Similar implementation on tensorflow [here](https://github.com/mrharicot/monodepth) and presentation [here](http://visual.cs.ucl.ac.uk/pubs/monoDepth/), [paper](https://arxiv.org/pdf/1607.06349.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
