{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution AutoEncoder\n",
    "\n",
    "References:\n",
    "\n",
    "* https://gist.github.com/tomokishii/7ddde510edb1c4273438ba0663b26fc6\n",
    "* https://github.com/pkmital/tensorflow_tutorials\n",
    "* https://github.com/chiphuyen/tf-stanford-tutorials\n",
    "* https://blog.dominodatalab.com/imbalanced-datasets/\n",
    "* https://pgaleone.eu/neural-networks/2016/11/24/convolutional-autoencoders/\n",
    "* https://pgaleone.eu/neural-networks/deep-learning/2016/12/13/convolutional-autoencoders-in-tensorflow/\n",
    "* https://swarbrickjones.wordpress.com/2015/04/29/convolutional-autoencoders-in-pythontheanolasagne/\n",
    "* https://gist.github.com/Newmu/a56d5446416f5ad2bbac\n",
    "* https://gist.github.com/kastnerkyle/f3f67424adda343fef40\n",
    "* https://github.com/Kaixhin/Autoencoders\n",
    "* https://github.com/siavashk/imagenet-autoencoder\n",
    "* https://siavashk.github.io/2016/02/22/autoencoder-imagenet/\n",
    "* http://torch.ch/blog/2015/11/13/gan.html\n",
    "* https://github.com/andreaazzini/segnet\n",
    "* https://github.com/tkuanlun350/Tensorflow-SegNet\n",
    "* https://github.com/shekkizh/FCN.tensorflow\n",
    "* http://techtalks.tv/talks/fully-convolutional-networks-for-semantic-segmentation/61606/\n",
    "* https://github.com/xiaofanglegoc/tensorflow-fcn\n",
    "* https://www.robots.ox.ac.uk/~vgg/rg/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf\n",
    "* http://stackoverflow.com/questions/36548736/tensorflow-unpoolingtensorflow/tensorflow#2169\n",
    "* https://arxiv.org/pdf/1412.7062.pdf\n",
    "* https://arxiv.org/pdf/1511.07122.pdf\n",
    "* https://hackernoon.com/autoencoders-deep-learning-bits-1-11731e200694"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Force to see just the first GPU\n",
    "# https://devblogs.nvidia.com/parallelforall/cuda-pro-tip-control-gpu-visibility-cuda_visible_devices/\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2d Convolution\n",
    "def conv2d(x, k_h, k_w, channels_in, channels_out, stride, act_type='relu', name=\"conv\", viewWeights=False):\n",
    "    with tf.name_scope(name):\n",
    "        # Define weights\n",
    "        w = tf.Variable(tf.truncated_normal([k_h,k_w, channels_in, channels_out], stddev=0.1), name=\"weights\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[channels_out]), name=\"bias\")    \n",
    "        # Convolution\n",
    "        #conv = tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='SAME')    \n",
    "        conv = tf.nn.conv2d(x, w, strides=[1, stride, stride, 1], padding='SAME')    \n",
    "                \n",
    "        # Relu or sigmoid\n",
    "        if act_type == 'relu':\n",
    "            activation = tf.nn.relu(conv + b)\n",
    "        else:\n",
    "            activation = tf.sigmoid(conv + b)\n",
    "        \n",
    "        # Add summaries for helping debug\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"bias\", b)\n",
    "        tf.summary.histogram(\"activation\", activation)\n",
    "        \n",
    "        # Visualize weights if needed\n",
    "        if viewWeights == True:                        \n",
    "            tf.summary.image(\"W_grid\", put_kernels_on_grid(w,3,8), 1)            \n",
    "            \n",
    "        return activation\n",
    "\n",
    "# 2d Transposed convolution (Deconvolution)\n",
    "def conv2d_transpose(x, out_size, k_h, k_w, channels_in, channels_out, stride, act_type='relu', name=\"deconv\"):\n",
    "    with tf.name_scope(name):\n",
    "        # Define weights (Notice that out/in channels are swapped on transposed conv)\n",
    "        w = tf.Variable(tf.truncated_normal([k_h,k_w, channels_out, channels_in], stddev=0.1), name=\"weights\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[channels_out]), name=\"bias\")    \n",
    "        \n",
    "        # Image output shape\n",
    "        shape4D = [tf.shape(x)[0], out_size[0], out_size[1], channels_out]\n",
    "        # Deconvolution (Transposed convolution)\n",
    "        conv = tf.nn.conv2d_transpose(x, w, output_shape=shape4D, strides=[1, stride, stride, 1], padding='SAME')                \n",
    "        \n",
    "        # Relu or sigmoid\n",
    "        if act_type == 'relu':\n",
    "            activation = tf.nn.relu(conv + b)\n",
    "        else:\n",
    "            activation = tf.sigmoid(conv + b)\n",
    "        \n",
    "        # Add summaries for helping debug\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"bias\", b)\n",
    "        tf.summary.histogram(\"activation\", activation)                \n",
    "            \n",
    "        return activation    \n",
    "\n",
    "def max_pool(x, k_h, k_w, S, name=\"maxpool\"):\n",
    "    with tf.name_scope(name):\n",
    "        return tf.nn.max_pool(x, ksize=[1, k_h, k_w, 1],strides=[1, S, S, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def fc_layer(x, channels_in, channels_out, name=\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([channels_in, channels_out], stddev=0.1), name=\"weights\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[channels_out]), name=\"bias\")    \n",
    "        activation = tf.nn.relu(tf.matmul(x, w) + b)\n",
    "        # Add summaries for helping debug\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"bias\", b)\n",
    "        tf.summary.histogram(\"activation\", activation)\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input placeholders\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10]) \n",
    "\n",
    "# Reshape to MNIST image dimensions 28x28x1\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "# K_y,K_x,in_depth,out_depth,stride\n",
    "conv1_out = conv2d(x_image, 3, 3, 1, 16, 1, act_type='relu', name=\"conv1\")        \n",
    "pool1_out = max_pool(conv1_out, 2, 2, 2, \"pool1\")        \n",
    "conv2_out = conv2d(pool1_out, 3, 3, 16, 8, 1, act_type='relu', name=\"conv2\")        \n",
    "pool2_out = max_pool(conv2_out, 2, 2, 2, \"pool2\")        \n",
    "conv3_out = conv2d(pool2_out, 3, 3, 8, 8, 1, act_type='relu', name=\"conv3\")    \n",
    "pool3_out = max_pool(conv3_out, 2, 2, 2, \"pool3\")\n",
    "\n",
    "# at this point the representation is (8, 4, 4) i.e. 128-dimensional\n",
    "# Decoding phase    \n",
    "conv_t1_out = conv2d_transpose(pool3_out, (7, 7), 3, 3, 8, 8, 2, act_type='relu', name=\"dconv1\")        \n",
    "conv_t2_out = conv2d_transpose(conv_t1_out, (14, 14), 3, 3, 8, 8, 2, act_type='relu', name=\"dconv2\")        \n",
    "conv_t3_out = conv2d_transpose(conv_t2_out, (28, 28), 3, 3, 8, 16, 2, act_type='relu', name=\"dconv3\")        \n",
    "\n",
    "decoded_img = conv2d(conv_t3_out, 3, 3, 16, 1, 1,act_type='sigmoid',name=\"conv4\")        \n",
    "\n",
    "# Convert spatial result to a vector in order to match with input \"x\" shape\n",
    "decoded = tf.reshape(decoded_img, [-1, 784])\n",
    "\n",
    "# Reshape for summary\n",
    "decoded_img_sumary = tf.reshape(decoded_img, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'output:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary cross-entropy\n",
    "with tf.name_scope(\"cross_entropy\"):\n",
    "    cross_entropy = -1. *x *tf.log(decoded) - (1. - x) *tf.log(1. - decoded)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Solver configuration\n",
    "with tf.name_scope(\"Solver\"):\n",
    "    train_step = tf.train.AdagradOptimizer(0.1).minimize(loss)  \n",
    "\n",
    "# Add summary for loss, input images, output images\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "tf.summary.image(\"input\", x_image, 10)\n",
    "tf.summary.image(\"output\", decoded_img_sumary, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Avoid allocating the whole memory\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "#sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"/tmp/conv_autoencoder/1\")\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "  step, loss =      0:  0.619\n",
      "  step, loss =   1000:  0.161\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "with sess:    \n",
    "    print('Training...')\n",
    "    for i in range(10001):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(128)\n",
    "        train_step.run({x: batch_xs, y_: batch_ys})\n",
    "        if i % 1000 == 0:\n",
    "            train_loss= loss.eval({x: batch_xs, y_: batch_ys})\n",
    "            print('  step, loss = %6d: %6.3f' % (i, train_loss))\n",
    "        \n",
    "        # Dump summary (Avoid dump every iteration)\n",
    "        if i % 100 == 0:\n",
    "            s = sess.run(merged_summary, feed_dict={x:batch_xs, y_: batch_ys})\n",
    "            writer.add_summary(s,i) \n",
    "\n",
    "    # generate decoded image with test data\n",
    "    #test_fd = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "    #decoded_imgs = decoded.eval(test_fd)\n",
    "    #print('loss (test) = ', loss.eval(test_fd))\n",
    "    \n",
    "    batch_xs_val, _ = mnist.test.next_batch(128)\n",
    "    #decoded_imgs = decoded.eval(feed_dict={x:mnist.test.images})\n",
    "    #print('loss (test) = ', loss.eval(feed_dict={x:mnist.test.images}))\n",
    "    # Avoid restarting my work PC\n",
    "    decoded_imgs = decoded.eval(feed_dict={x:batch_xs_val})\n",
    "    print('loss (test) = ', loss.eval(feed_dict={x:batch_xs_val}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x_test = mnist.test.images\n",
    "x_test = batch_xs_val\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('mnist_ae2.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
